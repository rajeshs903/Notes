
Name	age	build_start_date
x1	23	8/16/2018 12:08:00
x2	24	8/16/2018 12:33:00
x3	25	8/16/2018 15:21:00
x4	26	8/17/2018 15:04:00
x5	27	8/17/2018 15:04:00
x6	28	8/17/2018 15:11:00
x7	29	8/17/2018 15:13:00
x8	30	8/17/2018 15:04:00
x9	31	8/21/2018 9:51:00
x10	32	8/21/2018 11:34:00
x11	33	8/23/2018 13:16:00
x12	34	8/17/2018 15:04:00
x13	35	8/27/2018 18:59:00
x14	36	8/27/2018 20:06:00
x15	37	8/17/2018 15:04:00


Name,age,build_start_date
x1,23,8/16/2018 12:08:00
x2,24,8/16/2018 12:33:00
x3,25,8/16/2018 15:21:00
x4,26,8/17/2018 15:04:00
x5,27,8/17/2018 15:04:00
x6,28,8/17/2018 15:11:00
x7,29,8/17/2018 15:13:00
x8,30,8/17/2018 15:04:00
x9,31,8/21/2018 9:51:00
x10,32,8/21/2018 11:34:00
x11,33,8/23/2018 13:16:00
x12,34,8/17/2018 15:04:00
x13,35,8/27/2018 18:59:00
x14,36,8/27/2018 20:06:00
x15,37,8/17/2018 15:04:00


Question : change this to hive date timestamp format


hive (default)> create database rajeshs_task_db;
OK
Time taken: 1.246 seconds
hive (default)>
hive (default)> use  rajeshs_task_db;
OK
Time taken: 0.274 seconds
hive (rajeshs_task_db)>

create table test1
(name String,
age int,
joined DATE 
)
row format delimited fields terminated by ","
stored as textfile;

  hive (rajeshs_task_db)>
                      > create table test1
                      > (name String,
                      > age int,
                      > joined DATE
                      > )
                      > row format delimited fields terminated by ","
                      > stored as textfile;
OK
Time taken: 0.663 seconds
hive (rajeshs_task_db)> load data local inpath ('/home/rajeshs/datasets/build11.txt') into table test1;
FAILED: ParseException line 1:23 extraneous input '(' expecting StringLiteral near '<EOF>'
hive (rajeshs_task_db)> load data local inpath '/home/rajeshs/datasets/build11.txt' into table test1;
Loading data to table rajeshs_task_db.test1
Table rajeshs_task_db.test1 stats: [numFiles=1, numRows=0, totalSize=420, rawDataSize=0]
OK
Time taken: 1.193 seconds
hive (rajeshs_task_db)>


hive (rajeshs_task_db)> select * from test1;
OK
Name    NULL    NULL
x1      23      NULL
x2      24      NULL
x3      25      NULL
x4      26      NULL
x5      27      NULL
x6      28      NULL
x7      29      NULL
x8      30      NULL
x9      31      NULL
x10     32      NULL
x11     33      NULL
x12     34      NULL
x13     35      NULL
x14     36      NULL
x15     37      NULL
Time taken: 0.467 seconds, Fetched: 16 row(s)

tblproperties ("skip.header.line.count"="1");

hive (rajeshs_task_db)> create table test2
                      > (name String,
                      > age int,
                      > joined DATE
                      > )
                      > row format delimited fields terminated by ","
                      > stored as textfile
                      > tblproperties ("skip.header.line.count"="1");
OK
Time taken: 0.348 seconds
hive (rajeshs_task_db)> load data local inpath '/home/rajeshs/datasets/build11.txt' into table test2;
Loading data to table rajeshs_task_db.test2
Table rajeshs_task_db.test2 stats: [numFiles=1, numRows=0, totalSize=420, rawDataSize=0]
OK
Time taken: 1.035 seconds
hive (rajeshs_task_db)>
hive (rajeshs_task_db)> select * from test2;
OK
x1      23      NULL
x2      24      NULL
x3      25      NULL
x4      26      NULL
x5      27      NULL
x6      28      NULL
x7      29      NULL
x8      30      NULL
x9      31      NULL
x10     32      NULL
x11     33      NULL
x12     34      NULL
x13     35      NULL
x14     36      NULL
x15     37      NULL
Time taken: 0.381 seconds, Fetched: 15 row(s)

#skipped headers



hive (rajeshs_retail_db)> alter table test2 CHANGE joined joined STRING ;


hive (rajeshs_task_db)> select joined from test2;
OK
8/16/2018 12:08:00
8/16/2018 12:33:00
8/16/2018 15:21:00
8/17/2018 15:04:00
8/17/2018 15:04:00
8/17/2018 15:11:00
8/17/2018 15:13:00
8/17/2018 15:04:00
8/21/2018 9:51:00
8/21/2018 11:34:00
8/23/2018 13:16:00
8/17/2018 15:04:00
8/27/2018 18:59:00
8/27/2018 20:06:00
8/17/2018 15:04:00
Time taken: 0.328 seconds, Fetched: 15 row(s)


hive (rajeshs_task_db)> select  cast(to_date(from_unixtime(unix_timestamp(joined, 'dd/MM/yyyy'))) as date) from test2;
OK
2019-04-08
2019-04-08
2019-04-08
2019-05-08
2019-05-08
2019-05-08
2019-05-08
2019-05-08
2019-09-08
2019-09-08
2019-11-08
2019-05-08
2020-03-08
2020-03-08
2019-05-08
Time taken: 0.258 seconds, Fetched: 15 row(s)

select  (from_unixtime(unix_timestamp(joined, 'dd/MM/yyyy HH:mm:ss'))) from test2;


hive (rajeshs_task_db)> alter table test2 CHANGE joined joined1 TIMESTAMP ;
OK
Time taken: 0.322 seconds


select  to_date(from_unixtime(unix_timestamp(joined1, 'MM/dd/YYYY HH:mm:ss'))) from test2;

8/21/2018 11:34:00


select  cast(to_date(from_unixtime(unix_timestamp(joined1, 'dd/MM/yyyy'))) as date) from test2;

hive (rajeshs_retail_db)> alter table test2 CHANGE joined1 joined String ;


hive (rajeshs_task_db)> select  from_utc_timestamp(from_unixtime(unix_timestamp(joined, 'MM/dd/YYYY HH:mm:ss')),'America/Denver') from test2;
OK
2017-12-31 05:08:00
2017-12-31 05:33:00
2017-12-31 08:21:00
2017-12-31 08:04:00
2017-12-31 08:04:00
2017-12-31 08:11:00
2017-12-31 08:13:00
2017-12-31 08:04:00
2017-12-31 02:51:00
2017-12-31 04:34:00
2017-12-31 06:16:00
2017-12-31 08:04:00
2017-12-31 11:59:00
2017-12-31 13:06:00
2017-12-31 08:04:00
Time taken: 0.224 seconds, Fetched: 15 row(s)
hive (rajeshs_task_db)>



select  from_utc_timestamp((joined,'MM/dd/YYYY HH:mm:ss'),'America/Denver') from test2;


hive (rajeshs_task_db)> select  cast(from_utc_timestamp(from_unixtime(unix_timestamp(joined, 'MM/dd/YYYY HH:mm:ss')),'America/Denver') as timestamp) from test2;
OK
2017-12-31 05:08:00
2017-12-31 05:33:00
2017-12-31 08:21:00
2017-12-31 08:04:00
2017-12-31 08:04:00
2017-12-31 08:11:00
2017-12-31 08:13:00
2017-12-31 08:04:00
2017-12-31 02:51:00
2017-12-31 04:34:00
2017-12-31 06:16:00
2017-12-31 08:04:00
2017-12-31 11:59:00
2017-12-31 13:06:00
2017-12-31 08:04:00
Time taken: 0.351 seconds, Fetched: 15 row(s)




hive (rajeshs_task_db)> create table test3
                      > (name String,
                      > age int,
                      > m_date timestamp
                      > )
                      > row format delimited fields terminated by ","
                      > stored as textfile;
OK
Time taken: 0.478 seconds
hive (rajeshs_task_db)>

insert into test3 select name,age, cast(from_utc_timestamp(from_unixtime(unix_timestamp(joined, 'MM/dd/YYYY HH:mm:ss')),'America/Denver') as timestamp) from test2;



                      > insert into test3 select name,age, cast(from_utc_timestamp(from_unixtime(unix_timestamp(joined, 'MM/dd/YYYY HH:mm:ss')),'America/Denver') as timestamp) from test2;
Query ID = rajeshs_20180927150249_2bb3b9d6-6cf9-4c11-86dc-661f545302f8
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1533622723243_26955, Tracking URL = http://rm01.itversity.com:19288/proxy/application_1533622723243_26955/
Kill Command = /usr/hdp/2.6.5.0-292/hadoop/bin/hadoop job  -kill job_1533622723243_26955
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2018-09-27 15:02:57,977 Stage-1 map = 0%,  reduce = 0%
2018-09-27 15:03:03,220 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.63 sec
MapReduce Total cumulative CPU time: 2 seconds 630 msec
Ended Job = job_1533622723243_26955
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory hdfs://nn01.itversity.com:8020/apps/hive/warehouse/rajeshs_task_db.db/test3/.hive-staging_hive_2018-09-27_15-02-49_029_1250491210404872921-1/-ext-10000
Loading data to table rajeshs_task_db.test3
Table rajeshs_task_db.test3 stats: [numFiles=1, numRows=15, totalSize=396, rawDataSize=381]
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1   Cumulative CPU: 2.63 sec   HDFS Read: 5223 HDFS Write: 474 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 630 msec
OK
Time taken: 17.451 seconds



select  cast(date_format(from_unixtime(unix_timestamp(joined, 'dd/MM/YYYY HH:mm:ss'))) as timestamp) from test2;

hive (rajeshs_task_db)> select cast(from_utc_timestamp(from_unixtime(unix_timestamp(joined, 'MM/dd/yyyy HH:mm:ss')),'America/Denver') as timestamp) from test2;
OK
2018-08-16 06:08:00
2018-08-16 06:33:00
2018-08-16 09:21:00
2018-08-17 09:04:00
2018-08-17 09:04:00
2018-08-17 09:11:00
2018-08-17 09:13:00
2018-08-17 09:04:00
2018-08-21 03:51:00
2018-08-21 05:34:00
2018-08-23 07:16:00
2018-08-17 09:04:00
2018-08-27 12:59:00
2018-08-27 14:06:00
2018-08-17 09:04:00
Time taken: 0.23 seconds, Fetched: 15 row(s)


hive (rajeshs_task_db)> create table final_test1
                      > (name String,
                      > age int,
                      > m_date timestamp
                      > )
                      > row format delimited fields terminated by ","
                      > stored as textfile;
OK
Time taken: 0.312 seconds
hive (rajeshs_task_db)>


hive (rajeshs_task_db)> insert into final_test1 select name,age, cast(from_utc_timestamp(from_unixtime(unix_timestamp(joined, 'MM/dd/yyyy HH:mm:ss')),'America/Denver') as timestamp) from test2;


OK
Time taken: 16.302 seconds
hive (rajeshs_task_db)>




hive (rajeshs_task_db)> select * from final_test1;
OK
x1      23      2018-08-16 06:08:00
x2      24      2018-08-16 06:33:00
x3      25      2018-08-16 09:21:00
x4      26      2018-08-17 09:04:00
x5      27      2018-08-17 09:04:00
x6      28      2018-08-17 09:11:00
x7      29      2018-08-17 09:13:00
x8      30      2018-08-17 09:04:00
x9      31      2018-08-21 03:51:00
x10     32      2018-08-21 05:34:00
x11     33      2018-08-23 07:16:00
x12     34      2018-08-17 09:04:00
x13     35      2018-08-27 12:59:00
x14     36      2018-08-27 14:06:00
x15     37      2018-08-17 09:04:00
Time taken: 0.241 seconds, Fetched: 15 row(s)
hive (rajeshs_task_db)> describe final_test1;
OK
name                    string
age                     int
m_date                  timestamp
Time taken: 0.606 seconds, Fetched: 3 row(s)
hive (rajeshs_task_db)>
